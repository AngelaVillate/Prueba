{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L87MU9uHcsD2",
        "outputId": "100a73fe-994c-4e35-8c35-833b4d267a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " PASO 1: Instalando librerías...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            " Librerías instaladas correctamente\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\" PASO 1: Instalando librerías...\")\n",
        "!pip install PyPDF2 spacy -q\n",
        "!python -m spacy download es_core_news_sm -q\n",
        "\n",
        "print(\" Librerías instaladas correctamente\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" PASO 2: Importando librerías...\")\n",
        "\n",
        "import PyPDF2\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import unicodedata\n",
        "\n",
        "print(\" Librerías importadas correctamente\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyCToN1ye_LI",
        "outputId": "4074cdd9-a98c-4028-a9c0-d4242256378a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " PASO 2: Importando librerías...\n",
            " Librerías importadas correctamente\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PASO 3: Leyendo el PDF...\")\n",
        "\n",
        "ruta_pdf = '/content/Manual-de-escritura-jurídica-6-17.pdf'\n",
        "\n",
        "try:\n",
        "    with open(ruta_pdf, 'rb') as archivo:\n",
        "        lector_pdf = PyPDF2.PdfReader(archivo)\n",
        "        num_paginas = len(lector_pdf.pages)\n",
        "\n",
        "        print(f\"   Número de páginas: {num_paginas}\")\n",
        "\n",
        "        # Extraer texto de todas las páginas\n",
        "        texto_completo = \"\"\n",
        "        for i, pagina in enumerate(lector_pdf.pages):\n",
        "            texto_completo += pagina.extract_text()\n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(f\"   Procesadas {i + 1} páginas...\")\n",
        "\n",
        "        print(f\"PDF leído correctamente\\n\")\n",
        "        print(f\"Caracteres totales extraídos: {len(texto_completo)}\\n\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\" Error: No se encontró el archivo PDF\")\n",
        "    print(\"   Asegúrate de que el archivo esté en /content/\")\n",
        "    texto_completo = \"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gluSm22WfJ0q",
        "outputId": "1630d640-8f76-420b-8d6a-4725dedede8e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PASO 3: Leyendo el PDF...\n",
            "   Número de páginas: 12\n",
            "   Procesadas 10 páginas...\n",
            "PDF leído correctamente\n",
            "\n",
            "Caracteres totales extraídos: 68272\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" PASO 4: Normalizando Unicode...\")\n",
        "\n",
        "# Normalizar a NFD (descomponer caracteres con acentos)\n",
        "texto_nfd = unicodedata.normalize('NFD', texto_completo)\n",
        "print(f\"   Forma NFD: {len(texto_nfd)} caracteres\")\n",
        "\n",
        "# Normalizar a NFC (forma canónica compuesta)\n",
        "texto_nfc = unicodedata.normalize('NFC', texto_completo)\n",
        "print(f\"   Forma NFC: {len(texto_nfc)} caracteres\")\n",
        "\n",
        "# Usar NFC para el procesamiento\n",
        "texto_procesado = texto_nfc\n",
        "print(\"Texto normalizado a Unicode NFC\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT0Cj8JVfYVm",
        "outputId": "23503ef3-6950-477f-f0c8-85214d8956f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " PASO 4: Normalizando Unicode...\n",
            "   Forma NFD: 69499 caracteres\n",
            "   Forma NFC: 68272 caracteres\n",
            "Texto normalizado a Unicode NFC\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PASO 5: Tokenización\n",
        "print(\" PASO 5: Tokenizando el texto...\")\n",
        "\n",
        "# Cargar modelo de español\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "# Tokenizar (spaCy hace esto automáticamente)\n",
        "doc = nlp(texto_procesado)\n",
        "\n",
        "# Obtener tokens\n",
        "tokens = [token.text for token in doc]\n",
        "print(f\"   Total de tokens: {len(tokens)}\")\n",
        "print(f\"   Primeros 20 tokens: {tokens[:20]}\")\n",
        "print(\" Tokenización completada\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M9_MUBqffm7",
        "outputId": "5517d60f-8749-4ccf-fc20-1644b672c9ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " PASO 5: Tokenizando el texto...\n",
            "   Total de tokens: 14830\n",
            "   Primeros 20 tokens: ['PRIMERA', 'EDICIÓN6', '•Introducción', '\\n', 'El', '\\t', 'tráfico', '\\t', 'jurídico', '\\t', 'en', '\\t', 'Colombia', '\\t', 'es', '\\t', 'muy', '\\t', 'denso', '.']\n",
            " Tokenización completada\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PASO 6: Contando palabras SIN stop words...\")\n",
        "\n",
        "# Filtrar: solo palabras (sin puntuación ni espacios) y sin stop words\n",
        "palabras_sin_stop = [\n",
        "    token.text.lower()\n",
        "    for token in doc\n",
        "    if token.is_alpha and not token.is_stop\n",
        "]\n",
        "\n",
        "print(f\"   Total de palabras (sin stop words): {len(palabras_sin_stop)}\")\n",
        "\n",
        "# Contar frecuencias\n",
        "contador_sin_stop = Counter(palabras_sin_stop)\n",
        "mas_comunes_sin_stop = contador_sin_stop.most_common(20)\n",
        "\n",
        "print(\"\\n   Top 20 palabras más frecuentes (SIN stop words):\")\n",
        "for palabra, frecuencia in mas_comunes_sin_stop:\n",
        "    print(f\"      {palabra}: {frecuencia}\")\n",
        "\n",
        "print(\" Conteo sin stop words completado\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwaakZnrgqy4",
        "outputId": "98665fd0-370d-4727-9568-59dfc0207ee2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PASO 6: Contando palabras SIN stop words...\n",
            "   Total de palabras (sin stop words): 4821\n",
            "\n",
            "   Top 20 palabras más frecuentes (SIN stop words):\n",
            "      derecho: 76\n",
            "      lenguaje: 69\n",
            "      escritura: 40\n",
            "      abogados: 38\n",
            "      jurídico: 37\n",
            "      legal: 30\n",
            "      palabras: 28\n",
            "      estilo: 27\n",
            "      jurídica: 25\n",
            "      colombia: 22\n",
            "      lengua: 20\n",
            "      redacción: 20\n",
            "      español: 18\n",
            "      writing: 18\n",
            "      escritos: 17\n",
            "      disponible: 17\n",
            "      escrito: 17\n",
            "      judicial: 15\n",
            "      libro: 15\n",
            "      general: 15\n",
            " Conteo sin stop words completado\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" PASO 7: Contando palabras CON stop words...\")\n",
        "\n",
        "# Filtrar: solo palabras (sin puntuación ni espacios)\n",
        "palabras_con_stop = [\n",
        "    token.text.lower()\n",
        "    for token in doc\n",
        "    if token.is_alpha\n",
        "]\n",
        "\n",
        "print(f\"   Total de palabras (con stop words): {len(palabras_con_stop)}\")\n",
        "\n",
        "# Contar frecuencias\n",
        "contador_con_stop = Counter(palabras_con_stop)\n",
        "mas_comunes_con_stop = contador_con_stop.most_common(20)\n",
        "\n",
        "print(\"\\n    Top 20 palabras más frecuentes (CON stop words):\")\n",
        "for palabra, frecuencia in mas_comunes_con_stop:\n",
        "    print(f\"      {palabra}: {frecuencia}\")\n",
        "\n",
        "print(\"Conteo con stop words completado\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fslO_xJxgvd2",
        "outputId": "e81cfb58-b0e5-4858-9d85-378cb4832e85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " PASO 7: Contando palabras CON stop words...\n",
            "   Total de palabras (con stop words): 9921\n",
            "\n",
            "    Top 20 palabras más frecuentes (CON stop words):\n",
            "      de: 682\n",
            "      la: 423\n",
            "      en: 336\n",
            "      y: 310\n",
            "      el: 277\n",
            "      que: 217\n",
            "      los: 171\n",
            "      del: 160\n",
            "      a: 123\n",
            "      se: 119\n",
            "      un: 110\n",
            "      las: 108\n",
            "      es: 91\n",
            "      por: 91\n",
            "      para: 87\n",
            "      una: 77\n",
            "      derecho: 76\n",
            "      lenguaje: 69\n",
            "      como: 63\n",
            "      no: 61\n",
            "Conteo con stop words completado\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PASO 8: Identificar Entidades Nombradas (NER)\n",
        "print(\" PASO 8: Identificando entidades nombradas (NER)...\")\n",
        "\n",
        "# Extraer entidades\n",
        "entidades = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "print(f\"   Total de entidades encontradas: {len(entidades)}\")\n",
        "\n",
        "# Contar tipos de entidades\n",
        "tipos_entidades = Counter([label for _, label in entidades])\n",
        "\n",
        "print(\"\\n    Tipos de entidades encontradas:\")\n",
        "for tipo, cantidad in tipos_entidades.most_common():\n",
        "    print(f\"      {tipo}: {cantidad}\")\n",
        "\n",
        "# Mostrar ejemplos de cada tipo\n",
        "print(\"\\n    Ejemplos de entidades por tipo:\")\n",
        "entidades_por_tipo = {}\n",
        "for texto, label in entidades:\n",
        "    if label not in entidades_por_tipo:\n",
        "        entidades_por_tipo[label] = []\n",
        "    entidades_por_tipo[label].append(texto)\n",
        "\n",
        "for tipo, ejemplos in entidades_por_tipo.items():\n",
        "    ejemplos_unicos = list(set(ejemplos))[:5]  # 5 ejemplos únicos\n",
        "    print(f\"\\n      {tipo}:\")\n",
        "    for ejemplo in ejemplos_unicos:\n",
        "        print(f\"         - {ejemplo}\")\n",
        "\n",
        "print(\"\\n Identificación de NER completada\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_81JZTj1kbDp",
        "outputId": "dfcbfd32-a15d-4884-c977-2dcf5d609b1c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " PASO 8: Identificando entidades nombradas (NER)...\n",
            "   Total de entidades encontradas: 551\n",
            "\n",
            "    Tipos de entidades encontradas:\n",
            "      MISC: 217\n",
            "      LOC: 174\n",
            "      PER: 107\n",
            "      ORG: 53\n",
            "\n",
            "    Ejemplos de entidades por tipo:\n",
            "\n",
            "      MISC:\n",
            "         - La evidencia de los lingüistas\n",
            "         - La enseñanza artesanal de la escritura profesional buscó convertirse\n",
            "         - Sorprendería\n",
            "         - Ello ocurre\n",
            "         - Independencias\n",
            "\n",
            "      PER:\n",
            "         - Saussure\n",
            "         - Thomson\n",
            "         - tesis\tde\tSantiago\tMuñoz\tMachado\n",
            "         - Wets\n",
            "         - pública41\n",
            "\n",
            "      ORG:\n",
            "         - Agencia Nacional de Defensa Jurídica del Estado\n",
            "         - “¿Cuántos\n",
            "         - Unesco\n",
            "         - UNICEF\n",
            "         - Senado\n",
            "\n",
            "      LOC:\n",
            "         - Jueces\n",
            "         - Queremos\n",
            "         - idioma38\n",
            "         - Estados Unidos\n",
            "         - Chicago\n",
            "\n",
            " Identificación de NER completada\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q0kUyl8dkvOL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}